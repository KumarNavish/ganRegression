{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import dataset, metrics, plotting, config, network\n",
    "from models import cgan_model\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "importlib.reload(network)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(config)\n",
    "importlib.reload(cgan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_config = config.DatasetConfig(scenario=\"census-house\")\n",
    "\n",
    "assert(dataset_config.scenario == \"CA-housing\"\n",
    "      or dataset_config.scenario == \"ailerons\"\n",
    "      or dataset_config.scenario == \"CA-housing-single\"\n",
    "      or dataset_config.scenario == \"comp-activ\"\n",
    "      or dataset_config.scenario == \"pumadyn\"\n",
    "      or dataset_config.scenario == \"bank\"\n",
    "      or dataset_config.scenario == \"abalone\"\n",
    "      or dataset_config.scenario == \"census-house\")\n",
    "fig_dir = f\"../figures/{dataset_config.scenario}\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(fig_dir)\n",
    "    print(f\"Directory {fig_dir} created \") \n",
    "except FileExistsError:\n",
    "    print(f\"Directory {fig_dir} already exists replacing files in this notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1985\n",
    "\n",
    "if dataset_config.scenario == \"CA-housing\" or dataset_config.scenario == \"CA-housing-single\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.001, dec_gen=0, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )\n",
    "    \n",
    "elif dataset_config.scenario == \"ailerons\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.0005, dec_gen=0, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )\n",
    "    \n",
    "elif dataset_config.scenario == \"comp-activ\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.005, lr_disc=0.001, dec_gen=0.0001, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )\n",
    "    \n",
    "elif dataset_config.scenario == \"pumadyn\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.001, lr_disc=0.001, dec_gen=0.001, dec_disc=0.001, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )\n",
    "    \n",
    "elif dataset_config.scenario == \"bank\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.001, lr_disc=0.001, dec_gen=0.001, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )\n",
    "    \n",
    "elif dataset_config.scenario == \"abalone\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.001, lr_disc=0.001, dec_gen=0.001, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )\n",
    "    \n",
    "elif dataset_config.scenario == \"census-house\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.001, lr_disc=0.001, dec_gen=0.0001, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(exp_config.model.random_seed)\n",
    "random.seed(exp_config.model.random_seed)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(exp_config.model.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(scenario=exp_config.dataset.scenario, \n",
    "                                                                         seed=exp_config.model.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 1,eta=0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 2000)\n",
    "xg_reg.fit(X_train_scaled,y_train)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "ypred_xg_test = xg_reg.predict(X_test_scaled)\n",
    "xg_mae = mean_absolute_error(ypred_xg_test, y_test)\n",
    "print(xg_mae)\n",
    "\n",
    "cov_xg = np.mean((y_test - ypred_xg_test)**2)\n",
    "print(metrics.gaussian_NLPD(y_test, ypred_xg_test, np.ones(len(ypred_xg_test)) * cov_xg, \"XG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan = cgan_model.CGAN(exp_config)\n",
    "d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true = cgan.train(X_train_scaled, y_train, \n",
    "                                                                              epochs=exp_config.training.n_epochs,\n",
    "                                                                              batch_size=exp_config.training.batch_size)\n",
    "\n",
    "ypred_gan_test = cgan.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plots(d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true, fig_dir, exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_mean_gan_test, ypred_median_gan_test, ypred_gan_sample_test = cgan.sample(X_test_scaled, \n",
    "                                                                                exp_config.training.n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_mean_gan_train, ypred_median_gan_train, ypred_gan_sample_train = cgan.sample(X_train_scaled, \n",
    "                                                                                   exp_config.training.n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Comparable architecture to GAN \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(500, activation=\"relu\", input_shape=X_train_scaled.shape[1:]),\n",
    "    keras.layers.Dropout(dropout_rate), \n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dropout(dropout_rate), \n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dropout(dropout_rate),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dropout(dropout_rate),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dropout(dropout_rate),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dropout(dropout_rate),\n",
    "    keras.layers.Dense(1, activation=\"linear\"),\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(lr=0.001, decay=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(patience=10)]\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    validation_data=(X_valid_scaled, y_valid), epochs=100,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_nn_test = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "\n",
    "run_hyperopt_search = True\n",
    "rbf = True\n",
    "\n",
    "if rbf:\n",
    "    kernel = GPy.kern.RBF(input_dim=cgan.x_input_size, variance=variance, lengthscale=length)\n",
    "else:\n",
    "    kernel = GPy.kern.sde_RatQuad(input_dim=X_train_scaled.shape[1], variance=variance, lengthscale=length, power=power)\n",
    "\n",
    "gpr = GPy.models.GPRegression(X_train_scaled, y_train.reshape(-1, 1), kernel, noise_var=noise_var)\n",
    "\n",
    "if run_hyperopt_search:\n",
    "    gpr.optimize(messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_gp_test, cov_test = gpr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting.plot_densities_joint(y_test, ypred_nn_test, ypred_mean_gan_test, ypred_gp_test, \n",
    "#                              \"Linear-vs-GAN-vs-GP P(y) density\", fig_dir=fig_dir, \n",
    "#                              prefix=\"all_marginalized\", save_fig=exp_config.run.save_fig, at_x=True)\n",
    "\n",
    "plotting.plot_datadistrib_joint(y_test, ypred_nn_test, ypred_mean_gan_test, ypred_gp_test, \n",
    "                                \"Linear-vs-GAN-vs-GP P(y) density\", fig_dir=fig_dir, \n",
    "                                prefix=\"all_marginalized\", save_fig=exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mse_gan_= []\n",
    "mae_gan_ = []\n",
    "for i in range(n_eval_runs):\n",
    "    ypred_mean_gan_test_, ypred_median_gan_test_, _ = cgan.sample(X_test_scaled, exp_config.training.n_samples)\n",
    "    mae_gan_.append(mean_absolute_error(y_test, ypred_median_gan_test_))\n",
    "    mse_gan_.append(mean_squared_error(y_test, ypred_mean_gan_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mae = mean_absolute_error(ypred_nn_test, y_test)\n",
    "gp_mae = mean_absolute_error(ypred_gp_test, y_test)\n",
    "gan_mae_mean = np.mean(np.asarray(mae_gan_))\n",
    "gan_mae_std = np.std(np.asarray(mae_gan_))\n",
    "\n",
    "print(f\"NN MAE test: {nn_mae}\")\n",
    "print(f\"GP MAE test: {gp_mae}\")\n",
    "print(f\"GAN MAE test: {gan_mae_mean} +- {gan_mae_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mse = mean_squared_error(ypred_nn_test, y_test)\n",
    "gp_mse = mean_squared_error(ypred_gp_test, y_test)\n",
    "gan_mse_mean = np.mean(np.asarray(mse_gan_))\n",
    "gan_mse_std = np.std(np.asarray(mse_gan_))\n",
    "mdn_mse_mean = np.mean(np.asarray(mse_mdn_))\n",
    "mdn_mse_std = np.std(np.asarray(mse_mdn_))\n",
    "\n",
    "print(f\"NN MSE test: {nn_mse}\")\n",
    "print(f\"GP MSE test: {gp_mse}\")\n",
    "print(f\"GAN MSE test: {gan_mse_mean} +- {gan_mse_std}\")\n",
    "print(f\"MDN MSE test: {mdn_mse_mean} +- {mdn_mse_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_nn = np.mean((y_test - ypred_nn_test)**2)\n",
    "nn_nlpd = metrics.gaussian_NLPD(y_test, ypred_nn_test, np.ones(len(ypred_nn_test)) * cov_nn, \"NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_nlpd = metrics.gaussian_NLPD(y_test, ypred_gp_test, cov_test, \"GP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_nlpd_train, w, lls = metrics.Parzen(cgan, X_valid_scaled, y_valid, n_sample=exp_config.training.n_samples)\n",
    "nlpd_ = []\n",
    "for i in range(n_eval_runs):\n",
    "    nlpd_.append(metrics.Parzen_test(cgan, X_test_scaled, y_test, w, exp_config.training.n_samples))\n",
    "gan_nlpd_test = np.mean(nlpd_)\n",
    "gan_nlpd_std_test = np.std(nlpd_)\n",
    "\n",
    "print(f\"GAN Train NLLH: {gan_nlpd_train}\")\n",
    "print(f\"GAN Test NLLH: mean {gan_nlpd_test} std {gan_nlpd_std_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_config.run.save_fig:\n",
    "    file = open(f\"{fig_dir}/metrics.txt\",\"w\") \n",
    "\n",
    "    file.write(f\"===Test MAE===\\n\")\n",
    "    file.write(f\"NN MAE test: {nn_mae}\\n\") \n",
    "    file.write(f\"GP MAE test: {gp_mae}\\n\")\n",
    "    file.write(f\"GAN MAE test: {gan_mae_mean} +- {gan_mae_std}\\n\")\n",
    "    file.write(f\"===Test MSE===\\n\")\n",
    "    file.write(f\"NN MSE test: {nn_mse}\\n\")\n",
    "    file.write(f\"GP MSE test: {gp_mse}\\n\")\n",
    "    file.write(f\"GAN MSE test: {gan_mse_mean} +- {gan_mse_std}\\n\")\n",
    "    file.write(f\"===Test NLPD===\\n\")\n",
    "    file.write(f\"NN Gaussian NLPD: {nn_nlpd}\\n\")\n",
    "    file.write(f\"GP Gaussian NLPD: {gp_nlpd}\\n\")\n",
    "    file.write(f\"GAN NLPD: {gan_nlpd_test} +- {gan_nlpd_std_test}\\n\")\n",
    "    file.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
