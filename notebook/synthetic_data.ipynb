{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import dataset, metrics, plotting, config\n",
    "from models import cgan_model\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(config)\n",
    "importlib.reload(cgan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_config = config.DatasetConfig(scenario=\"heteroscedastic\", n_instance=1000)\n",
    "\n",
    "assert(dataset_config.scenario == \"linear\" \n",
    "       or dataset_config.scenario == \"sinus\"\n",
    "       or dataset_config.scenario == \"heteroscedastic\"\n",
    "       or dataset_config.scenario == \"exp\"\n",
    "       or dataset_config.scenario == \"multi-modal\"\n",
    "      )\n",
    "fig_dir = f\"../figures/{dataset_config.scenario}\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(fig_dir)\n",
    "    print(f\"Directory {fig_dir} created \") \n",
    "except FileExistsError:\n",
    "    print(f\"Directory {fig_dir} already exists replacing files in this notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = config.Config(\n",
    "    model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, dec_gen=0, lr_disc=0.001, optim_gen=\"Adam\", \n",
    "                             optim_disc=\"Adam\", z_input_size=1),\n",
    "    training=config.TrainingConfig(n_epochs=2000, batch_size=100, n_samples=100),\n",
    "    dataset=dataset_config,\n",
    "    run=config.RunConfig(save_fig=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(exp_config.model.random_seed)\n",
    "random.seed(exp_config.model.random_seed)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(exp_config.model.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_valid, y_valid = dataset.get_dataset(exp_config.dataset.n_instance, \n",
    "                                                                         exp_config.dataset.scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_dataset(X_train, X_test, X_valid, y_train, y_test, y_valid, exp_config, fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 1,eta=0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 2000)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "#y_pred2 = xg_reg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "ypred_xg_test = xg_reg.predict(X_test)\n",
    "xg_mae = mean_absolute_error(ypred_xg_test, y_test)\n",
    "print(xg_mae)\n",
    "\n",
    "\n",
    "cov_xg = np.mean((y_test - ypred_xg_test)**2)\n",
    "print(metrics.gaussian_NLPD(y_test, ypred_xg_test, np.ones(len(ypred_xg_test)) * cov_xg, \"XG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "mae = []\n",
    "ll = []\n",
    "\n",
    "for i in range(10):\n",
    "    #kerner_initializer = keras.initializers.he_uniform(seed=exp_config.model.random_seed)\n",
    "    dropout_rate = 0.1\n",
    "    #use lr of 0.005 for ailerons\n",
    "    # Architecture 3\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]), #, kernel_initializer=kerner_initializer),\n",
    "        keras.layers.Dropout(dropout_rate), #, seed=exp_config.model.random_seed),\n",
    "        keras.layers.Dense(50, activation=\"relu\"), #, kernel_initializer=kerner_initializer),\n",
    "        keras.layers.Dropout(dropout_rate), #, seed=exp_config.model.random_seed),\n",
    "        keras.layers.Dense(50, activation=\"relu\"), #, kernel_initializer=kerner_initializer),\n",
    "        keras.layers.Dropout(dropout_rate), #, seed=exp_config.model.random_seed),\n",
    "        keras.layers.Dense(50, activation=\"relu\"), #, kernel_initializer=kerner_initializer),\n",
    "        keras.layers.Dropout(dropout_rate), #, seed=exp_config.model.random_seed),\n",
    "        keras.layers.Dense(50, activation=\"relu\"), #, kernel_initializer=kerner_initializer),\n",
    "        keras.layers.Dropout(dropout_rate), #, seed=exp_config.model.random_seed),\n",
    "        keras.layers.Dense(50, activation=\"relu\"), #, kernel_initializer=kerner_initializer),\n",
    "        keras.layers.Dropout(dropout_rate), #, seed=exp_config.model.random_seed),\n",
    "        keras.layers.Dense(1, activation=\"linear\"), #, kernel_initializer=kerner_initializer)\n",
    "    ])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(lr=0.005, decay=0.0))\n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=10)]\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_valid, y_valid), epochs=100,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    ypred_nn_test = model.predict(X_test)\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    nn_mae = mean_absolute_error(ypred_nn_test, y_test)\n",
    "    print(nn_mae)\n",
    "    mae.append(nn_mae)\n",
    "    cov_nn = np.mean((y_test - ypred_nn_test)**2)\n",
    "    nn_nlpd = metrics.gaussian_NLPD(y_test, ypred_nn_test, np.ones(len(ypred_nn_test)) * cov_nn, \"NN\")\n",
    "    ll.append(nn_nlpd)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(ll))\n",
    "print(np.mean(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "ypred_linear_test = regr.predict(X_test)\n",
    "ypred_linear_train = regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "\n",
    "noise = 1\n",
    "length = 1\n",
    "\n",
    "run_hyperopt_search = True\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=1, variance=noise, lengthscale=length)\n",
    "gpr = GPy.models.GPRegression(X_train, y_train, kernel)\n",
    "if run_hyperopt_search:\n",
    "    gpr.optimize(messages=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_gp_test, cov_test = gpr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan = cgan_model.CGAN(exp_config)\n",
    "d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true = cgan.train(X_train, y_train, \n",
    "                                                                              epochs=exp_config.training.n_epochs,\n",
    "                                                                              batch_size=exp_config.training.batch_size)\n",
    "\n",
    "ypred_gan_test = cgan.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plots(d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true, fig_dir, exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_mean_gan_test, ypred_median_gan_test, ypred_gan_sample_test = cgan.sample(X_test, exp_config.training.n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_ypred_joint(X_test, y_test, ypred_linear_test, ypred_mean_gan_test, ypred_gp_test, \n",
    "                          \"Linear-vs-GAN-vs-GP Mean Test Predictions\", fig_dir=fig_dir, prefix=\"all_mean\", \n",
    "                          save_fig=exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single GAN sample\n",
    "plotting.plot_ypred_joint(X_test, y_test, ypred_linear_test, ypred_gan_test, ypred_gp_test, \n",
    "                          \"Linear-vs-GAN-vs-GP Test Single GAN sample\", fig_dir=fig_dir, prefix=\"gan_single_sample\", \n",
    "                          save_fig=exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_contours = 2\n",
    "\n",
    "plot_contours = False\n",
    "\n",
    "if plot_contours:\n",
    "    # Sample from GP P(Y|X)\n",
    "    ypred_gp_sample_test = np.random.normal(ypred_gp_test, np.sqrt(cov_test))\n",
    "    for i in range(1, sample_size_contours):\n",
    "        ypred_gp_sample_test = np.vstack([ypred_gp_sample_test, np.random.normal(ypred_gp_test, np.sqrt(cov_test))])\n",
    "    \n",
    "    # Sample from GAN\n",
    "    _, _, ypred_gan_sample_test = cgan.sample(X_test, sample_size_contours)\n",
    "    \n",
    "    plotting.plot_density_cont(X_test, y_test, title=\"True contours\", fig_dir=fig_dir, prefix=\"true_sample\", \n",
    "                               save_fig=exp_config.run.save_fig)\n",
    "    plotting.plot_density_cont(np.tile(X_test, plotting_sample_size), ypred_gp_sample_test, title=\"GP contours\", \n",
    "                               fig_dir=fig_dir, prefix=\"gp_sample\", save_fig=exp_config.run.save_fig)\n",
    "    plotting.plot_density_cont(np.tile(X_test, plotting_sample_size), ypred_gan_sample_test, title=\"GAN contours\", \n",
    "                               fig_dir=fig_dir, prefix=\"gan_sample\", save_fig=exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_densities_joint(y_test, ypred_linear_test, ypred_mean_gan_test, ypred_gp_test, \n",
    "                              \"Marginalized P(y) density\", fig_dir=fig_dir, prefix=\"all_marginalized\", \n",
    "                              save_fig=exp_config.run.save_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display predictions with more samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_sample_size = 2 # inscrease sample_size to have gaussian densities for GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, X_test_sample, y_test_sample, _, _ = dataset.get_dataset(exp_config.dataset.n_instance * 5, \n",
    "                                                               exp_config.dataset.scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_mean_gan_full_test, ypred_median_gan_full_test, ypred_gan_sample_full_test = cgan.sample(X_test_sample, \n",
    "                                                                                               plotting_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_gp_test_full, cov_test_full = gpr.predict(X_test_sample)\n",
    "\n",
    "ypred_gp_sample_full_test = np.random.normal(ypred_gp_test_full[0], np.sqrt(cov_test_full[0]))\n",
    "for i in range(1, len(X_test_sample)):\n",
    "    ypred_gp_sample_full_test = np.vstack([ypred_gp_sample_full_test, \n",
    "                                           np.random.normal(ypred_gp_test_full[i], np.sqrt(cov_test_full[i]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if exp_config.dataset.scenario == \"linear\":\n",
    "    ylim=[-10, 15]\n",
    "elif exp_config.dataset.scenario == \"sinus\" or exp_config.dataset.scenario == \"heteroscedastic\":\n",
    "    ylim=[-4, 4]\n",
    "elif exp_config.dataset.scenario == \"exp\":\n",
    "    ylim=[-4, 9]\n",
    "elif exp_config.dataset.scenario == \"multi-modal\":\n",
    "    ylim=[-0.1, 1.1]\n",
    "else:\n",
    "    raise Exception(\"Y limits to be specified\")\n",
    "    \n",
    "plotting.plot_ypred_joint(X_test_sample, y_test_sample, None, None, None, \"True Sample\", alpha=0.15, is_sample=True, \n",
    "                          fig_dir=fig_dir, prefix=\"true_more_sample\", save_fig=exp_config.run.save_fig, ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_ypred_joint(X_test_sample, None, None, ypred_gan_sample_full_test, None, \n",
    "                          \"GAN Test Predictions\", alpha=0.25, is_sample=True, fig_dir=fig_dir, \n",
    "                          prefix=\"gan_more_sample\", save_fig=exp_config.run.save_fig, ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_ypred_joint(X_test_sample, None, None, None, ypred_gp_sample_full_test, \"GP Test Predictions\", \n",
    "                          alpha=0.15, is_sample=False, fig_dir=fig_dir, prefix=\"gp_more_sample\", \n",
    "                          save_fig=exp_config.run.save_fig, ylim=ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P(y|x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if exp_config.dataset.scenario == \"sinus\":\n",
    "    bins = [-1, 0, 1]\n",
    "    ylim = [[-2.5,2.5], [-2.5,2.5], [-2.5,2.5]]\n",
    "elif exp_config.dataset.scenario == \"linear\":\n",
    "    bins = [4, 0, 10] \n",
    "    ylim = [[-5,17.5], [-5,17.5], [5,22]]\n",
    "elif exp_config.dataset.scenario == \"exp\":\n",
    "    bins = [-1, 0, 1] \n",
    "    ylim = [[-5,17.5], [-5,17.5], [5,22]]\n",
    "elif exp_config.dataset.scenario == \"multi-modal\":\n",
    "    bins = [0.4, 0.45, 0.2]\n",
    "    ylim = [[0,1.1], [0,1], [0,1.1]]\n",
    "elif exp_config.dataset.scenario == \"heteroscedastic\":\n",
    "    bins = [-2,0,2]\n",
    "    ylim = [[-3.2,2], [-2,2], [-2,5.5]]\n",
    "else:\n",
    "    raise Exception(\"Bins to be specified\")\n",
    "\n",
    "ind = 0\n",
    "delta = 0.05\n",
    "\n",
    "for x in bins:\n",
    "    idx = np.logical_and(X_test_sample < x + delta, X_test_sample > x - delta)\n",
    "    ypred_gan_sample_ = ypred_gan_sample_full_test[:, 0].reshape(-1,1)\n",
    "    ypred_gp_sample_ = ypred_gp_sample_full_test[:, 0].reshape(-1,1)\n",
    "    plotting.plot_densities_joint(y_test_sample[idx], None, ypred_gan_sample_[idx], ypred_gp_sample_[idx], \n",
    "                                  f\"P(y|x) density at x={x}\", at_x=True, fig_dir=fig_dir, prefix=f\"all_at_x_{x}\", \n",
    "                                  save_fig=exp_config.run.save_fig, ylim=ylim[ind])\n",
    "    ind = ind + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mse_gan_= []\n",
    "mae_gan_ = []\n",
    "for i in range(n_eval_runs):\n",
    "    ypred_mean_gan_test_, ypred_median_gan_test_, _ = cgan.sample(X_test, exp_config.training.n_samples)\n",
    "    mae_gan_.append(mean_absolute_error(y_test, ypred_median_gan_test_))\n",
    "    mse_gan_.append(mean_squared_error(y_test, ypred_mean_gan_test_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_mae_mean = np.mean(np.asarray(mae_gan_))\n",
    "gan_mae_std = np.std(np.asarray(mae_gan_))\n",
    "\n",
    "print(f\"Linear MAE test: {mean_absolute_error(ypred_linear_test, y_test)}\")\n",
    "print(f\"GP MAE test: {mean_absolute_error(ypred_gp_test, y_test)}\")\n",
    "print(f\"GAN MAE test: {gan_mae_mean} +- {gan_mae_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_mse = mean_squared_error(ypred_linear_test, y_test)\n",
    "gp_mse = mean_squared_error(ypred_gp_test, y_test)\n",
    "gan_mse_mean = np.mean(np.asarray(mse_gan_))\n",
    "gan_mse_std = np.std(np.asarray(mse_gan_))\n",
    "\n",
    "print(f\"Linear MSE test: {linear_mse}\")\n",
    "print(f\"GP MSE test: {gp_mse}\")\n",
    "print(f\"GAN MSE test: {gan_mse_mean} +- {gan_mse_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_nlpd = metrics.gaussian_NLPD(y_test, ypred_linear_test, np.ones(len(ypred_linear_test)), \"Linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_nlpd = metrics.gaussian_NLPD(y_test, ypred_gp_test, cov_test, \"GP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_nlpd_train, w, lls = metrics.Parzen(cgan, X_valid, y_valid)\n",
    "nlpd_ = []\n",
    "for i in range(n_eval_runs):\n",
    "    nlpd_.append(metrics.Parzen_test(cgan, X_test, y_test, w, exp_config.training.n_samples))\n",
    "gan_nlpd_test = np.mean(nlpd_)\n",
    "gan_nlpd_std_test = np.std(nlpd_)\n",
    "print(f\"GAN Train NLPD: {gan_nlpd_train}\")\n",
    "print(f\"GAN Test NLPD: mean {gan_nlpd_test} std {gan_nlpd_std_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exp_config.run.save_fig:\n",
    "    file = open(f\"{fig_dir}/metrics.txt\",\"w\") \n",
    "\n",
    "    file.write(f\"===Test MAE===\\n\")\n",
    "    file.write(f\"Linear MAE test: {mean_absolute_error(ypred_linear_test, y_test)}\\n\") \n",
    "    file.write(f\"GP MAE test: {mean_absolute_error(ypred_gp_test, y_test)}\\n\")\n",
    "    file.write(f\"GAN MAE test: {gan_mae_mean} +- {gan_mae_std}\\n\")\n",
    "    file.write(f\"===Test MSE===\\n\")\n",
    "    file.write(f\"Linear MSE test: {linear_mse}\\n\")\n",
    "    file.write(f\"GP MSE test: {gp_mse}\\n\")\n",
    "    file.write(f\"GAN MSE test: {gan_mse_mean} +- {gan_mse_std}\\n\")\n",
    "    file.write(f\"===Test NLPD===\\n\")\n",
    "    file.write(f\"Linear Gaussian NLPD: {linear_nlpd}\\n\")\n",
    "    file.write(f\"GP Gaussian NLPD: {gp_nlpd}\\n\")\n",
    "    file.write(f\"GAN NLPD: {gan_nlpd_test} +- {gan_nlpd_std_test}\\n\")\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
